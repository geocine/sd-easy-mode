{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q7lggNI5DEPX",
        "outputId": "e762ddbb-d61f-4a2d-de42-53705d2fb0e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              "  li img, p img {vertical-align: middle;}\n",
              "  .overview {font-size: 16px;}\n",
              "  .markdown :not(pre)>code {\n",
              "    background-color: #1e1e1e;\n",
              "    border-radius: 2px;\n",
              "    padding: 2px 5px;\n",
              "  }\n",
              "  .markdown code {\n",
              "      font-size: 90%;\n",
              "      color: white;\n",
              "  }\n",
              "</style>\n",
              "<body>\n",
              "<div class=\"markdown overview\">\n",
              "<p>With this Google Colab, you can train an AI text-to-image generator called <a href=\"https://en.wikipedia.org/wiki/Stable_Diffusion\" target=\"_blank\" rel=\"nofollow\">Stable Diffusion</a> to generate images that resemble the photos you provide as input</p>\n",
              "<p>To run a step, press the  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> and wait for it to finish. You will see a  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920487-aa67d823-7424-4613-b62d-74d4a4b4fb29.png\" alt=\"colab-check\"> on the left side of <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920376-2b18380b-f879-4326-bce6-8ac70fe3744b.png\" alt=\"play\"> when it is complete. Proceed to the next step. Steps 1-3 must be completed before using steps 4-5</p>\n",
              "<ol>\n",
              "<li>Setup - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> </li>\n",
              "<li>Upload - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> then <img src=\"https://user-images.githubusercontent.com/507464/210199321-28a6c380-1044-423f-a111-3ed96e5a8eb1.png\" alt=\"choose-files\"> will show. Start uploading your photos.</li>\n",
              "<li>Train - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will take around ~30 minutes to complete.</li>\n",
              "<li>Generate - Change <code>PROMPT</code> and other desired settings then press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. You can repeat this step as many times as you want without rerunning steps 1-3</li>\n",
              "<li>Save -  Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will save model to Google Drive, you must have at least 2GB free space to continue.</li>\n",
              "</ol>\n",
              "<p>This Colab is based on <a href=\"https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth\" target=\"_blank\" rel=\"nofollow\">ShivamShrirao's repository</a> and has been modified by <img src=\"https://user-images.githubusercontent.com/507464/213915305-35c7227c-639d-4480-b521-bd89ba6b0d09.png\" alt=\"youtube\"> <a href=\"https://github.com/geocine/sd-easy-mode\" target=\"_blank\" rel=\"nofollow\">geocine</a> to be more accessible to complete beginners. It is not intended for advanced or long-term use.</p>\n",
              "<p>You can watch <img src=\"https://user-images.githubusercontent.com/507464/213915097-b3d8450a-1011-4923-8782-867124b0c7a8.png\" alt=\"youtube\"> <a href=\"https://www.youtube.com/watch?v=HVOvL2CyBT0\" target=\"_blank\">this video</a> by <b>Nolan Aatama</b> on youtube to see how it works!</p>\n",
              "</span></div>\n",
              "</body>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown # Instructions\n",
        "%%html\n",
        "<style>\n",
        "  li img, p img {vertical-align: middle;}\n",
        "  .overview {font-size: 16px;}\n",
        "  .markdown :not(pre)>code {\n",
        "    background-color: #1e1e1e;\n",
        "    border-radius: 2px;\n",
        "    padding: 2px 5px;\n",
        "  }\n",
        "  .markdown code {\n",
        "      font-size: 90%;\n",
        "      color: white;\n",
        "  }\n",
        "</style>\n",
        "<body>\n",
        "<div class=\"markdown overview\">\n",
        "<p>With this Google Colab, you can train an AI text-to-image generator called <a href=\"https://en.wikipedia.org/wiki/Stable_Diffusion\" target=\"_blank\" rel=\"nofollow\">Stable Diffusion</a> to generate images that resemble the photos you provide as input</p>\n",
        "<p>To run a step, press the  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> and wait for it to finish. You will see a  <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920487-aa67d823-7424-4613-b62d-74d4a4b4fb29.png\" alt=\"colab-check\"> on the left side of <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920376-2b18380b-f879-4326-bce6-8ac70fe3744b.png\" alt=\"play\"> when it is complete. Proceed to the next step. Steps 1-3 must be completed before using steps 4-5</p>\n",
        "<ol>\n",
        "<li>Setup - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> </li>\n",
        "<li>Upload - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\"> then <img src=\"https://user-images.githubusercontent.com/507464/210199321-28a6c380-1044-423f-a111-3ed96e5a8eb1.png\" alt=\"choose-files\"> will show. Start uploading your photos.</li>\n",
        "<li>Train - Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will take around ~30 minutes to complete.</li>\n",
        "<li>Generate - Change <code>PROMPT</code> and other desired settings then press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. You can repeat this step as many times as you want without rerunning steps 1-3</li>\n",
        "<li>Save -  Press <img width=\"35\" height=\"35\" src=\"https://user-images.githubusercontent.com/507464/213920060-876eb760-bd99-485f-b594-dc1d04dfe0fa.gif\" alt=\"play\">. This will save model to Google Drive, you must have at least 2GB free space to continue.</li>\n",
        "</ol>\n",
        "<p>This Colab is based on <a href=\"https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth\" target=\"_blank\" rel=\"nofollow\">ShivamShrirao's repository</a> and has been modified by <img src=\"https://user-images.githubusercontent.com/507464/213915305-35c7227c-639d-4480-b521-bd89ba6b0d09.png\" alt=\"youtube\"> <a href=\"https://github.com/geocine/sd-easy-mode\" target=\"_blank\" rel=\"nofollow\">geocine</a> to be more accessible to complete beginners. It is not intended for advanced or long-term use.</p>\n",
        "<p>You can watch <img src=\"https://user-images.githubusercontent.com/507464/213915097-b3d8450a-1011-4923-8782-867124b0c7a8.png\" alt=\"youtube\"> <a href=\"https://www.youtube.com/watch?v=HVOvL2CyBT0\" target=\"_blank\">this video</a> by <b>Nolan Aatama</b> on Youtube to see how it works!</p>\n",
        "</span></div>\n",
        "</body>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "# You may change these settings if you know what you are doing\n",
        "BRANCH = \"main\" # Branch/Tag of the repository to use\n",
        "SDD_TOKEN = \"zwx\" # Token name for this subject, If you decide to change this later, you can just rerun this cell without any issues\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" # Base model you want to use, only diffusers model\n",
        "\n",
        "!wget -q -O easymode.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/easymode.py\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "from google.colab import output\n",
        "import warnings\n",
        "import time\n",
        "from easymode import ProgressBar, install_package, replace_tokens, download_regularization, print_message\n",
        "\n",
        "\n",
        "# Your JSON data\n",
        "concepts_list_data =   {\n",
        "    \"instance_prompt\": \"photo of {SDD_TOKEN} {SDD_CLASS}\",\n",
        "    \"class_prompt\": \"photo of {SDD_CLASS}\",\n",
        "    \"instance_data_dir\": \"/content/data/training_images\",\n",
        "    \"class_data_dir\": \"/content/data/{SDD_CLASS}\"\n",
        "}\n",
        "# Replace {SDD_TOKEN} with a SDD_TOKEN\n",
        "concepts_list_data[\"instance_prompt\"] = concepts_list_data[\"instance_prompt\"].replace(\"{SDD_TOKEN}\", SDD_TOKEN)\n",
        "concepts_list_data[\"instance_data_dir\"] = concepts_list_data[\"instance_data_dir\"].replace(\"{SDD_TOKEN}\", SDD_TOKEN)\n",
        "\n",
        "# Write the data to a file with proper indentation\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump([concepts_list_data], f, indent=2)\n",
        "\n",
        "# Disable the warning message\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
        "                        module=\"IPython.core.interactiveshell\")\n",
        "\n",
        "# GPU Check\n",
        "\n",
        "# @markdown The system checks for a compatible GPU with enough memory and installs necessary Python packages during setup.\n",
        "# Run the nvidia-smi command to get the VRAM information\n",
        "result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,memory.total,memory.free\",\n",
        "                        \"--format=csv,noheader\"], capture_output=True, check=True)\n",
        "\n",
        "# Split the output by newline characters to get a list of VRAM info for each GPU\n",
        "vram_info = result.stdout.decode(\"utf-8\").strip().split(\"\\n\")\n",
        "\n",
        "# Parse the VRAM info for each GPU\n",
        "for info in vram_info:\n",
        "    name, total, free = info.split(\",\")\n",
        "    total = int(total.strip().split()[0])  # Total VRAM in MB\n",
        "    free = int(free.strip().split()[0])  # Free VRAM in MB\n",
        "\n",
        "    print(f\"GPU: {name}, Total VRAM: {total} MB, Free VRAM: {free} MB\")\n",
        "\n",
        "if total < 15109:  # 15109MB is equivalent to 15GB\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[91mError: Not enough VRAM available. Please change the runtime to a GPU with at least 15GB VRAM.\\033[0m\")\n",
        "    raise SystemExit\n",
        "else:\n",
        "    print(\"\\033[92mYou have enough VRAM to continue\\033[0m\")\n",
        "\n",
        "# Installation\n",
        "\n",
        "!wget -q -O train_dreambooth.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/train_dreambooth.py\n",
        "!wget -q -O convert_diffusers_to_original_stable_diffusion.py https://github.com/geocine/sd-easy-mode/raw/{BRANCH}/convert_diffusers_to_original_stable_diffusion.py\n",
        "\n",
        "# URLs of the diffusers and xformers packages\n",
        "# DIFFUSERS_URL = 'git+https://github.com/huggingface/diffusers.git@244e16a7abfabce9e606b950af349062df40e437'\n",
        "DIFFUSERS_URL = 'git+https://github.com/ShivamShrirao/diffusers'\n",
        "XFORMERS_URL = 'https://github.com/geocine/dreamstall-binaries/releases/download/cxx-p38-txx-linux/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl'\n",
        "\n",
        "# List of packages to check and install\n",
        "packages = ['diffusers', 'triton', 'accelerate==0.12.0',\n",
        "            'transformers', 'ftfy', 'bitsandbytes==0.35.0', 'xformers']\n",
        "\n",
        "# Check and install each package\n",
        "pb = ProgressBar(len(packages), \"Installing\")\n",
        "for package in packages:\n",
        "    label = install_package(package, DIFFUSERS_URL, XFORMERS_URL, \"exp\", False)\n",
        "    pb.update(label)\n",
        "print(\"\\033[92mInstallation complete\\033[0m\")\n",
        "\n",
        "!mkdir -p ~/.cache/huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\"\n",
        "\n",
        "# check if HUGGINGFACE_TOKEN is set\n",
        "if not HUGGINGFACE_TOKEN:\n",
        "    # Display an error message in red text\n",
        "    print_message(\"warning\", \"Please set HUGGINGFACE_TOKEN first.\")\n",
        "\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.cache/huggingface/token\n",
        "\n",
        "OUTPUT_DIR = f\"stable_diffusion_models/{SDD_TOKEN}\"\n",
        "OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(\"config.json\", \"w\") as f:\n",
        "    # Write the data to the file in indent format\n",
        "    json.dump({\"model_name\": MODEL_NAME, \"output_dir\": OUTPUT_DIR}, f, indent=4)\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    # Remove all files and directories inside the directory using the rm command\n",
        "    subprocess.run([\"rm\", \"-rf\", f\"{OUTPUT_DIR}/*\"], check=True)\n",
        "else:\n",
        "    # Create the directory\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(f\"[*] Models will be saved at {OUTPUT_DIR}\")\n",
        "os.makedirs(\"/content/data/training_images\", exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0W530tWf904D"
      },
      "source": [
        "# Upload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "# @markdown To train the model, run this cell to upload 15-20 images of your subject. The images should be 512x512 in size and show the subject in various poses, expressions, and backgrounds. The images should show the subject in different variations. If your images are not already 512x512, you can use [this tool](https://www.birme.net/?target_width=512&target_height=512) to resize them in a batch.<br><br>\n",
        "# @markdown You can also upload directly on the `/data/training_images` folder on the file explorer which is faster than using the upload button below.\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    print_message(\"warning\", \"Please run the Setup cell first\")\n",
        "\n",
        "replace_tokens(\"/content/concepts_list.json\", SDD_TOKEN)\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "# Incorporate this so that users won't have to crop their images https://github.com/d8ahazard/sd_smartprocess\n",
        "for c in concepts_list:\n",
        "    prompt = c['instance_prompt']\n",
        "    prompt = prompt.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=\"\")\n",
        "    print(f\"Uploading instance images for `{prompt}`\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "      print_message(\"error\",\"Please run the Upload step again and select the images you want to use\")\n",
        "    else:\n",
        "      for filename in uploaded.keys():\n",
        "          dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "          # Create the instance_data_dir directory if it does not exist\n",
        "          os.makedirs(c['instance_data_dir'], exist_ok=True)\n",
        "          shutil.move(filename, dst_path)\n",
        "\n",
        "print(\"\\033[92mImages have been uploaded. If you need to add more, simply run this cell again\\033[0m\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eh"
      },
      "outputs": [],
      "source": [
        "!cp /usr/local/cuda/lib64/libcudart.so /usr/lib64-nvidia\n",
        "\n",
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    print_message(\"warning\", \"Please run the Setup cell first\")\n",
        "\n",
        "from easymode import ProgressBar, create_interpolation_function, replace_tokens, download_regularization, print_message\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)[0]\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Open the file in read mode\n",
        "with open(\"/content/config.json\", \"r\") as f:\n",
        "    # Load the JSON data from the file\n",
        "    config = json.load(f)\n",
        "\n",
        "# Assign the value of the \"model_name\" property to the MODEL_NAME variable\n",
        "MODEL_NAME = config[\"model_name\"]\n",
        "OUTPUT_DIR = config[\"output_dir\"]\n",
        "\n",
        "os.environ['BITSANDBYTES_NOWELCOME'] = \"1\"\n",
        "# @markdown The number of steps is currently set to auto-compute(-1), but you can adjust them to try and improve accuracy. More steps usually improve accuracy, but too many can cause the model to overfit and perform poorly on other tasks like styling. Fewer steps may result in less accurate models. Only change these settings if you understand the potential consequences and are familiar with the process. If you do adjust the number of steps, make small changes and test the model's performance.\n",
        "\n",
        "MAX_TRAIN_STEPS = -1  # @param {type:\"number\"}\n",
        "SDD_CLASS = \"person\" #@param [\"person\", \"man\", \"woman\", \"dog\", \"cat\", \"artstyle\"]\n",
        "SAVE_SAMPLE_PROMPT = \"photo of {TOKEN_CLASS}\"\n",
        "SAVE_SAMPLE_PROMPT = SAVE_SAMPLE_PROMPT.format(\n",
        "    TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "\n",
        "# @markdown `SDD_CLASS` is the subject type you want to train.<br><br>\n",
        "# @markdown The default value for `SDD_CLASS` is `person`. For example, if you set `SDD_CLASS` to `dog` then use the prompt `zwx dog` on the **Generate** step.\n",
        "\n",
        "replace_tokens(\"/content/concepts_list.json\", SDD_TOKEN, SDD_CLASS)\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "num_images = 0\n",
        "\n",
        "c = concepts_list[0]\n",
        "data_dir = c['instance_data_dir']\n",
        "# replace the SDD_TOKEN placeholders with the actual values\n",
        "data_dir = data_dir.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=\"\")\n",
        "# Check if the directory exists\n",
        "if os.path.exists(data_dir):\n",
        "    # Check if the directory is empty\n",
        "    num_files = len(os.listdir(data_dir))\n",
        "    if num_files == 0:\n",
        "        print_message(\"error\", f\"The directory `{data_dir}` is empty. Please upload some images using the Upload step above.\")\n",
        "    else:\n",
        "        num_images += num_files\n",
        "else:\n",
        "    # Raise an exception if the directory does not exist\n",
        "    print_message(\"error\", f\"The directory `{data_dir}` does not exist. Please run the Upload cell first\")\n",
        "# interpolation computation based on Astria results\n",
        "interpolate_max_train_steps = create_interpolation_function(\n",
        "    [(10, 1611), (11, 1750), (15, 2281)])\n",
        "\n",
        "\n",
        "# You may change these settings if you know what you are doing\n",
        "\n",
        "NUM_CLASS_IMAGES = num_images * 10\n",
        "if MAX_TRAIN_STEPS < 0:\n",
        "    MAX_TRAIN_STEPS = int(interpolate_max_train_steps(num_images))\n",
        "\n",
        "regularizations = [SDD_CLASS]\n",
        "\n",
        "for regularization in regularizations:\n",
        "    download_regularization(regularization)\n",
        "\n",
        "SAVE_INTERVAL = 10000\n",
        "SAVE_MIN_STEPS = 0\n",
        "CLEAR_MODELS = True\n",
        "SAMPLE_BATCH_SIZE = 4\n",
        "\n",
        "\n",
        "# Check SAVE_MIN_STEPS should be should be less than or equal MAX_TRAIN_STEPS\n",
        "if SAVE_MIN_STEPS > MAX_TRAIN_STEPS:\n",
        "    print_message(\"error\", \"Your model will not be saved if SAVE_MIN_STEPS is greater than MAX_TRAIN_STEPS.\")\n",
        "\n",
        "PRE_GENERATE = None\n",
        "g_cuda = None\n",
        "\n",
        "# Write the data to a file with proper indentation\n",
        "with open(\"settings.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"num_class_images\": NUM_CLASS_IMAGES,\n",
        "        \"sample_batch_size\": SAMPLE_BATCH_SIZE,\n",
        "        \"max_train_steps\": MAX_TRAIN_STEPS,\n",
        "        \"save_interval\": SAVE_INTERVAL,\n",
        "        \"save_min_steps\": SAVE_MIN_STEPS,\n",
        "        \"save_sample_prompt\": SAVE_SAMPLE_PROMPT\n",
        "    }, f, indent=2)\n",
        "\n",
        "if CLEAR_MODELS:\n",
        "    # Run the rm command using subprocess\n",
        "    subprocess.run(\n",
        "        [\"rm\", \"-rf\", f\"/content/stable_diffusion_models/*\"])\n",
        "\n",
        "!accelerate launch --num_processes=1 --num_machines=1 --mixed_precision=\"no\" --num_cpu_threads_per_process=1 train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "    --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "    --output_dir=$OUTPUT_DIR \\\n",
        "    --revision=\"fp16\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --seed=1337 \\\n",
        "    --resolution=512 \\\n",
        "    --train_batch_size=1 \\\n",
        "    --train_text_encoder \\\n",
        "    --mixed_precision=\"fp16\" \\\n",
        "    --use_8bit_adam \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=1e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "    --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
        "    --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "    --save_interval=$SAVE_INTERVAL \\\n",
        "    --save_min_steps=$SAVE_MIN_STEPS \\\n",
        "    --save_sample_prompt=\"$SAVE_SAMPLE_PROMPT\" \\\n",
        "    --concepts_list=\"concepts_list.json\"\n",
        "#   --shuffle_after_epoch\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# @markdown The default value for `SDD_CLASS` is `person`. If you trained a different class, update the prompts accordingly. For example, if you set `SDD_CLASS` to `dog` then replace `zwx {SDD_CLASS}` with `zwx dog`.<br><br>\n",
        "# @markdown To generate images, change the parameters and run the cell. Include `zwx {SDD_CLASS}` in your prompts. For example: `a photo of zwx {SDD_CLASS}`. If you want more prompt ideas, you can check out [Astria's gallery](https://www.astria.ai/gallery) and replace `sks|zwx person|man|woman` with `zwx {SDD_CLASS}`.<br><br>\n",
        "\n",
        "if not os.path.exists(f'/content/settings.json') or not os.path.exists(f'/content/concepts_list.json'):\n",
        "    print_message(\"error\", \"Please run the Setup step above.\")\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "import random\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, EulerDiscreteScheduler\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[0][\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[0][\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"settings.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Assign the value of MAX_TRAIN_STEPS from the JSON data to the MAX_TRAIN_STEPS variable\n",
        "MAX_TRAIN_STEPS = data[\"max_train_steps\"]\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "\n",
        "if not os.path.exists(f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "if 'PRE_GENERATE' not in globals():\n",
        "    PRE_GENERATE = None;\n",
        "\n",
        "if PRE_GENERATE is None or g_cuda is None:\n",
        "    print(\"Loading model...\")\n",
        "    PRE_GENERATE = False\n",
        "    # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "    model_path = f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'\n",
        "    model_path = model_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "    scheduler = EulerDiscreteScheduler(\n",
        "        num_train_timesteps=1000, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(model_path):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "SEED = -1\n",
        "if (SEED < 0):\n",
        "    SEED = random.randint(0, 2**32 - 1)\n",
        "g_cuda.manual_seed(SEED)\n",
        "\n",
        "\n",
        "PROMPT = \"closeup photo of zwx person, trending on artstation, by greg rutkowski, alphonse mucha\" # @param {type:\"string\"}\n",
        "PROMPT = PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\") \n",
        "NEGATIVE_PROMPT = \"ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, cloned face, disfigured, out of frame, extra limbs, bad anatomy, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, mutated hands, fused fingers, too many fingers, long neck, text, letters, signature, web address, copyright name, username, error, extra digit, fewer digits, loadscreen, grid, stock image, a stock photo, promo poster, fat\" # @param {type:\"string\"}\n",
        "NUM_IMAGES_PER_PROMPT = 4  # @param {type:\"number\"}\n",
        "GUIDANCE_SCALE = 7.5  # @param {type:\"number\"}\n",
        "INFERENCE_STEPS = 50  # @param {type:\"number\"}\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt=PROMPT,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_images_per_prompt=NUM_IMAGES_PER_PROMPT,\n",
        "        num_inference_steps=INFERENCE_STEPS,\n",
        "        guidance_scale=GUIDANCE_SCALE,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "text = \"\"\"\n",
        "<br>\n",
        "If you're not happy with the output, you can try adjusting the <code>GUIDANCE_SCALE</code> and <code>INFERENCE_STEPS</code> parameters to improve the accuracy and quality of the generated images. \n",
        "<br><br>\n",
        "If the model is not generating a likeness, try using higher quality reference photos or increasing the number of training steps, then starting the training process again.\n",
        "<br>\n",
        "<br>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(text))\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3EydphztWBiI"
      },
      "source": [
        "# Save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHvppaFtcFA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "if not os.path.exists(f'/content/settings.json') or not os.path.exists(f'/content/concepts_list.json'):\n",
        "    print_message(\"error\", \"Please run the Setup step above.\")\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"concepts_list.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the SDD_TOKEN value from the \"instance_prompt\" field\n",
        "instance_prompt = data[0][\"instance_prompt\"]\n",
        "SDD_TOKEN = instance_prompt.split(\" \")[-2]\n",
        "\n",
        "# Extract the SDD_CLASS value from the \"class_data_dir\" field\n",
        "class_data_dir = data[0][\"class_data_dir\"]\n",
        "SDD_CLASS = class_data_dir.split(\"/\")[-1]\n",
        "\n",
        "# Read the file and parse the JSON data\n",
        "with open(\"settings.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Assign the value of MAX_TRAIN_STEPS from the JSON data to the MAX_TRAIN_STEPS variable\n",
        "MAX_TRAIN_STEPS = data[\"max_train_steps\"]\n",
        "\n",
        "# @markdown This will save your trained model to your Google Drive. <font color=\"#1f76b6\" >Make sure you have 2GB free space</font>. You can then download it and use it offline with the desktop application [Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui). Please join [Stable Diffusion Dreambooth Discord](https://discord.com/invite/qbMuXBXyHA), we have a helpful community.<br><br>\n",
        "# @markdown **Note:** <font color=\"#1f76b6\" >If Google Colab crashes after running this, just run it again and it should succeed.</span>\n",
        "MODEL_STEPS = MAX_TRAIN_STEPS\n",
        "mdl_path = f\"/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}\"\n",
        "mdl_path = mdl_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "ckpt_path = mdl_path + \"/model.ckpt\"\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(mdl_path):\n",
        "    print_message(\"error\", f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training step above.\")\n",
        "\n",
        "if not os.path.exists(ckpt_path):\n",
        "    !python convert_diffusers_to_original_stable_diffusion.py --model_path $mdl_path --checkpoint_path $ckpt_path --half\n",
        "    print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "# Check if Google Drive is already mounted\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "NAME = \"me\"  # @param {type:\"string\"}\n",
        "# @markdown Enter the path to save the model in Google Drive. If left empty, the model will be saved in the root of Google Drive.\n",
        "GDRIVE_PATH = \"\"  # @param {type:\"string\"}\n",
        "# @markdown <font color=\"#1f76b6\" >It will take some time to appear on Google Drive, wait for 5 minutes</font>\n",
        "# remove / from start and end of GDRIVE_PATH if they exist\n",
        "GDRIVE_PATH = GDRIVE_PATH.strip('/')\n",
        "MODEL_NAME = f\"{NAME}-{SDD_CLASS}-{MODEL_STEPS}-{SDD_TOKEN}\"\n",
        "if GDRIVE_PATH:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{GDRIVE_PATH}/{MODEL_NAME}.ckpt\"\n",
        "else:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{MODEL_NAME}.ckpt\"\n",
        "\n",
        "# Execute the command\n",
        "!{cmd}\n",
        "if GDRIVE_PATH:\n",
        "    print(\n",
        "        f\"Model saved at /{GDRIVE_PATH}/{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "else:\n",
        "    print(\n",
        "        f\"Model saved at /{MODEL_NAME}.ckpt Wait for 5 minutes before closing\")\n",
        "\n",
        "print(\n",
        "    f\"To use your model on other applications make sure to mention \\\"{SDD_TOKEN} {SDD_CLASS}\\\" in the prompt.\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E3L4EhLn4Cb8"
      },
      "source": [
        "Here are some resources you may find helpful as you continue learning about Stable Diffusion Dreambooth:\n",
        "\n",
        "- [The guide to fine-tuning Stable Diffusion with your own images](https://tryolabs.com/blog/2022/10/25/the-guide-to-fine-tuning-stable-diffusion-with-your-own-images)\n",
        "- [Basic Dreambooth Guide](https://github.com/nitrosocke/dreambooth-training-guide)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "Y213v6IvcUvk"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "#@markdown If your session is running low on memory, you can run this cell. This will refresh your session and save your current work.\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ST",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "94adf441e4abda7873a0f7f8d10896673bf8eb743389c6db05f684353e1dc292"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
