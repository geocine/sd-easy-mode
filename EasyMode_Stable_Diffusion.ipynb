{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU7NuMAA2drw",
        "outputId": "3de37d2f-2ebb-42ca-918c-6123fbc9cf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tesla T4, 15109 MiB, 15109 MiB\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "from google.colab import output\n",
        "#@markdown Check type of GPU and VRAM available. Make sure we have atleast a Telsa T4 GPU.\n",
        "# Run the nvidia-smi command to get the VRAM information\n",
        "result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name,memory.total,memory.free\", \"--format=csv,noheader\"], capture_output=True, check=True)\n",
        "\n",
        "# Split the output by newline characters to get a list of VRAM info for each GPU\n",
        "vram_info = result.stdout.decode(\"utf-8\").strip().split(\"\\n\")\n",
        "\n",
        "# Parse the VRAM info for each GPU\n",
        "for info in vram_info:\n",
        "    name, total, free = info.split(\",\")\n",
        "    total = int(total.strip().split()[0])  # Total VRAM in MB\n",
        "    free = int(free.strip().split()[0])  # Free VRAM in MB\n",
        "    \n",
        "    print(f\"GPU: {name}, Total VRAM: {total} MB, Free VRAM: {free} MB\")\n",
        "\n",
        "if total < 15109:  # 15109MB is equivalent to 15GB\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[91mError: Not enough VRAM available. Please change the runtime to a GPU with at least 15GB VRAM.\\033[0m\")\n",
        "else:\n",
        "    print(\"\\033[92mYou have enough VRAM to continue\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTMyW41cC1E"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aLWXPZqjsZVV"
      },
      "outputs": [],
      "source": [
        "#@markdown Install dependencies. You don't need to change any of these settings. Make sure to run this before running any cells below.\n",
        "!wget -q -O train_dreambooth.py https://github.com/geocine/smd-diffusion/raw/main/train_dreambooth.py\n",
        "!wget -q -O convert_diffusers_to_original_stable_diffusion.py https://github.com/geocine/smd-diffusion/raw/main/convert_diffusers_to_original_stable_diffusion.py\n",
        "!wget -q -O concepts_list.json https://github.com/geocine/smd-diffusion/raw/main/concepts_list.json\n",
        "# URLs of the diffusers and xformers packages\n",
        "import subprocess\n",
        "from ipywidgets import IntProgress, HTML, HBox\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "class ProgressBar:\n",
        "    def __init__(self, num_items, label_text='Progress'):\n",
        "        self.num_items = num_items\n",
        "        self.start_time = time.perf_counter()\n",
        "        self.count = 0\n",
        "        self.label_text = label_text\n",
        "\n",
        "        # Create a progress bar and HTML widgets to display the labels and progress bar\n",
        "        self.f = IntProgress(min=0, max=num_items)\n",
        "        self.label1 = HTML(value=f'{label_text}: 0%')\n",
        "        self.label2 = HTML(value='', layout=dict(margin='2px 0 0 10px'))\n",
        "\n",
        "        # Group the widgets horizontally using the HBox layout\n",
        "        display(HBox([self.label1, self.f, self.label2]))\n",
        "\n",
        "    def update(self, label=''):\n",
        "        value = 1\n",
        "        self.count += value\n",
        "        self.f.value += value\n",
        "        percentage = f'{self.f.value / self.num_items * 100:.0f}'\n",
        "        self.label1.value = f'{self.label_text}: {percentage}%'\n",
        "        self.label2.value = label\n",
        "        # change bar color to green if done\n",
        "        if self.f.value == self.num_items:\n",
        "            self.f.bar_style = 'success'\n",
        "\n",
        "    def error(self, label=''):\n",
        "        self.label2.value = 'Stopped due to error'\n",
        "        self.f.bar_style = 'danger'\n",
        "\n",
        "DIFFUSERS_URL = 'git+https://github.com/ShivamShrirao/diffusers'\n",
        "XFORMERS_URL = 'https://github.com/geocine/dreamstall-binaries/releases/download/cxx-p38-txx-linux/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl'\n",
        "FORCE_REINSTALL = False #@param {type:\"boolean\"}\n",
        "\n",
        "def install_package(package, force_reinstall=False):\n",
        "    # Check if the package is already installed using pip freeze\n",
        "    installed_packages = subprocess.run([\"pip\", \"freeze\"], capture_output=True).stdout.decode().split(\"\\n\")\n",
        "    if not force_reinstall and any(package in s for s in installed_packages):\n",
        "        return f'{package} is already installed'\n",
        "\n",
        "    if package == 'diffusers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"-qq\", \"install\", DIFFUSERS_URL], capture_output=True, text=True, check=True)\n",
        "    elif package == 'xformers':\n",
        "        # Install the package using the URL\n",
        "        result = subprocess.run([\"pip\", \"install\", XFORMERS_URL], capture_output=True, text=True, check=True)\n",
        "    else:\n",
        "        # Install the package using pip\n",
        "        result = subprocess.run([\"pip\", \"install\", package], capture_output=True, text=True, check=True)\n",
        "\n",
        "    # Print the output of the command\n",
        "    # print(result.stdout)\n",
        "    return f'{package} is installed'\n",
        "# List of packages to check and install\n",
        "packages = ['diffusers', 'triton', 'accelerate==0.12.0', 'transformers', 'ftfy', 'bitsandbytes', 'xformers']\n",
        "\n",
        "# Check and install each package\n",
        "pb = ProgressBar(len(packages), \"Installing\")\n",
        "for package in packages:\n",
        "    label = install_package(package, FORCE_REINSTALL)\n",
        "    pb.update(label)\n",
        "print(\"\\033[92mInstallation complete\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0NV324ZcL9L"
      },
      "source": [
        "## Settings\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Details about <code>{SDD_TOKEN}</code> and <code>{SDD_CLASS}</code></summary>\n",
        "\n",
        "  - `SDD_TOKEN` - corresponds to the unique identifier which will reference the subject we want to add. This name should be unique, so we donâ€™t have to compete with an existing representation\n",
        "  - `SDD_CLASS` - use generic classes such as man, woman, or child (if the subject is a person) or cat or dog (if the subject is a pet)\n",
        "\n",
        "  > You could explore other classes. In this Colab I use the class `supermodel` by default since I get good results in training my personal subjects\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rxg0y5MBudmd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from huggingface_hub import hf_hub_download\n",
        "import subprocess\n",
        "import warnings\n",
        "\n",
        "# Disable the warning message\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"IPython.core.interactiveshell\")\n",
        "\n",
        "SDD_TOKEN = \"zwx\" #@param {type:\"string\"}\n",
        "SDD_CLASS = \"supermodel\" #@param {type:\"string\"}\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[93mPlease run the Install cell first\\033[0m\")\n",
        "    \n",
        "    # Raise a SystemExit exception to exit the cell\n",
        "    raise SystemExit\n",
        "\n",
        "# Open the JSON file and read the contents\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "  json_data = json.load(f)\n",
        "\n",
        "# Iterate over the object and replace the placeholders with the values\n",
        "for item in json_data:\n",
        "  for key, value in item.items():\n",
        "    item[key] = value.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "\n",
        "# Open the JSON file and write the updated contents\n",
        "with open(\"/content/concepts_list.json\", \"w\") as f:\n",
        "  json.dump(json_data, f, indent=2)\n",
        "\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "#@markdown You have to be a registered user in ðŸ¤— [Hugging Face](https://huggingface.co/), and you'll also need to use an [access token](https://huggingface.co/settings/tokens) for the code to work.\n",
        "\n",
        "# check if HUGGINGFACE_TOKEN is set\n",
        "if not HUGGINGFACE_TOKEN:\n",
        "    # Display an error message in red text\n",
        "    print(\"\\033[93mPlease set HUGGINGFACE_TOKEN first.\\033[0m\")\n",
        "    \n",
        "    # Raise a SystemExit exception to exit the cell\n",
        "    raise SystemExit\n",
        "\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "OUTPUT_DIR = f\"stable_diffusion_models/{SDD_TOKEN}\"\n",
        "OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "  # Change to the directory\n",
        "  os.chdir(OUTPUT_DIR)\n",
        "  # Remove all files and directories inside the directory using the rm command\n",
        "  subprocess.run([\"rm\", \"-rf\", \"*\"], check=True)\n",
        "else:\n",
        "  # Create the directory\n",
        "  os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "print(f\"[*] Models will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "unzip_directory = f\"/content/data/{SDD_CLASS}\"\n",
        "\n",
        "# Check if the unzip directory exists\n",
        "try:\n",
        "  # Get a list of the files in the unzip directory\n",
        "  files = os.listdir(unzip_directory)\n",
        "except FileNotFoundError:\n",
        "  # Create the unzip directory\n",
        "  os.makedirs(unzip_directory)\n",
        "  # Set the files list to an empty list\n",
        "  files = []\n",
        "\n",
        "#Downloading the regularization images\n",
        "zip_file = f\"{SDD_CLASS}.zip\"\n",
        "if not os.path.exists(zip_file):\n",
        "    try:\n",
        "        reg_url = f\"https://huggingface.co/datasets/geocine/sd-v1-5-regularization-images/resolve/main/{zip_file}\"\n",
        "        subprocess.run([\"wget\", \"-q\", reg_url], check=True)\n",
        "    except Exception as e:\n",
        "        # Print an error message and set the zip_file variable to None if the download fails or the user doesn't have access\n",
        "        print(f\"An error occurred while downloading the dataset: {e}\")\n",
        "        zip_file = None\n",
        "\n",
        "# Check if the unzip directory has files\n",
        "if len(files) > 0:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Unzip directory has files. Skipping unzip.\")\n",
        "elif zip_file is None:\n",
        "  # Do not run the unzip command\n",
        "  print(\"Skipping unzip because the zip file was not downloaded\")\n",
        "else:\n",
        "  command = f\"unzip -l {zip_file} | wc -l\" \n",
        "  result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  file_count = int(result.stdout.decode('utf-8').strip())\n",
        "  # Run the unzip command\n",
        "  pb = ProgressBar(file_count, \"Extracting\")\n",
        "  process = subprocess.Popen(\n",
        "    [\"unzip\", \"-j\", zip_file, \"-d\", unzip_directory], stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
        "  )\n",
        "  while process.poll() is None:\n",
        "    out = process.stdout.readline()\n",
        "    if out != '' :# and (b\"extracting\" in out):\n",
        "      current_file = out.decode(\"utf-8\").replace(\"extracting: \",\"\")\n",
        "      current_file = current_file.replace(\"inflating: \", \"\")\n",
        "      pb.update(current_file)\n",
        "  print(\"\\033[92mExtracting regularization images completed\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn5ILIyDJIcX"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32gYIDDR1aCp"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload your photos by running this cell. Make sure your photos are 512x512. You can batch resize your photos using [this tool](https://www.birme.net/?target_width=512&target_height=512)\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# check if /content/concepts_list.json exists if not remind to run install\n",
        "if not os.path.exists(\"/content/concepts_list.json\"):\n",
        "    raise ValueError(\"Please run the Install cell first\")\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "\n",
        "# Incorporate this so that users won't have to crop their images https://github.com/d8ahazard/sd_smartprocess\n",
        "for c in concepts_list:\n",
        "   prompt = c['instance_prompt']\n",
        "   prompt = prompt.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "   print(f\"Uploading instance images for `{prompt}`\")\n",
        "   uploaded = files.upload()\n",
        "   for filename in uploaded.keys():\n",
        "       dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "       # Create the instance_data_dir directory if it does not exist\n",
        "       os.makedirs(c['instance_data_dir'], exist_ok=True)\n",
        "       shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jjcSXTp-u-Eg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Load the data from the JSON file into the concepts_list variable\n",
        "with open(\"/content/concepts_list.json\", \"r\") as f:\n",
        "    concepts_list = json.load(f)\n",
        "\n",
        "num_images = 0\n",
        "\n",
        "for c in concepts_list:\n",
        "    data_dir = c['instance_data_dir']\n",
        "    # replace the SDD_TOKEN placeholders with the actual values\n",
        "    data_dir = data_dir.format(SDD_TOKEN=SDD_TOKEN, SDD_CLASS=SDD_CLASS)\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(data_dir):\n",
        "        # Check if the directory is empty\n",
        "        num_files = len(os.listdir(data_dir))\n",
        "        if num_files == 0:\n",
        "            raise ValueError(f\"The directory `{data_dir}` is empty. Please upload some images using the cell above.\")\n",
        "        else:\n",
        "            num_images += num_files\n",
        "    else:\n",
        "        # Raise an exception if the directory does not exist\n",
        "        raise ValueError(f\"The directory `{data_dir}` does not exist. Please run the Upload cell first.\")\n",
        "\n",
        "# count the number of images on the instance_data_dir\n",
        "\n",
        "# compute NUM_CLASS_IMAGES based on the number of images , num_images * 200 with a limit of 4000\n",
        "# min(num_images * 200, 4000)\n",
        "NUM_CLASS_IMAGES = 3000 #@param {type:\"number\"}\n",
        "#@markdown `{TOKEN_CLASS}` will be replaced with the token and class name.\n",
        "SAVE_SAMPLE_PROMPT = \"photo of {TOKEN_CLASS}\" #@param {type:\"string\"}\n",
        "SAVE_SAMPLE_PROMPT = SAVE_SAMPLE_PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "MAX_TRAIN_STEPS = 3000 #@param {type:\"number\"}\n",
        "SAVE_INTERVAL = 400 #@param {type:\"number\"}\n",
        "SAVE_MIN_STEPS = 2000 #@param {type:\"number\"}\n",
        "CLEAR_MODELS = True #@param {type:\"boolean\"}\n",
        "SAMPLE_BATCH_SIZE = 4\n",
        "\n",
        "\n",
        "# Check SAVE_MIN_STEPS should be should be less than or equal MAX_TRAIN_STEPS\n",
        "if SAVE_MIN_STEPS > MAX_TRAIN_STEPS:\n",
        "    raise ValueError(\"Your model will not be saved if SAVE_MIN_STEPS is greater than MAX_TRAIN_STEPS.\")\n",
        "\n",
        "#@markdown If you have experience with training models, you can change more parameters on the code in this cell.\n",
        "\n",
        "PREV_MODEL_STEPS = None\n",
        "g_cuda = None\n",
        "\n",
        "if CLEAR_MODELS:\n",
        "    # Run the rm command using subprocess\n",
        "    subprocess.run([\"rm\", \"-rf\", f\"/content/stable_diffusion_models/{SDD_TOKEN}/*\"])\n",
        "\n",
        "!accelerate launch train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"main\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
        "  --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
        "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
        "  --save_interval=$SAVE_INTERVAL \\\n",
        "  --save_min_steps=$SAVE_MIN_STEPS \\\n",
        "  --save_sample_prompt=\"$SAVE_SAMPLE_PROMPT\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n",
        "# --shuffle_after_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "xmvbPv0UJIag"
      },
      "outputs": [],
      "source": [
        "#@markdown Run to generate a grid of preview images from the last saved models.\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "if \"OUTPUT_DIR\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "models_folder = OUTPUT_DIR\n",
        "folders = sorted([f for f in os.listdir(models_folder) if f != \"0\"], key=lambda x: int(x))\n",
        "\n",
        "\n",
        "# Get the list of folders in the models folder and check if the samples folder exists and have images, the number of images should be equal to the SAMPLE_BATCH_SIZE\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(models_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    if not os.path.exists(image_folder):\n",
        "        raise ValueError(f\"The folder `{image_folder}` does not exist. Please make sure you have run the Training cell above.\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    if len(images) != SAMPLE_BATCH_SIZE:\n",
        "        raise ValueError(f\"The folder `{image_folder}` does not have {SAMPLE_BATCH_SIZE} images. Please make sure you have run the Training cell above.\")\n",
        "\n",
        "# Check if the number of folders > 0\n",
        "if len(folders) == 0:\n",
        "    raise ValueError(\"No folders found in the models folder. Please make sure you have run the training cell above.\")\n",
        "\n",
        "row = len(folders)\n",
        "col = len(os.listdir(os.path.join(models_folder, folders[0], \"samples\")))\n",
        "scale = 4\n",
        "fig, axes = plt.subplots(row, col, figsize=(col*scale, row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n",
        "\n",
        "for i, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(models_folder, folder)\n",
        "    image_folder = os.path.join(folder_path, \"samples\")\n",
        "    images = [f for f in os.listdir(image_folder)]\n",
        "    for j, image in enumerate(images):\n",
        "        if row == 1:\n",
        "            currAxes = axes[j]\n",
        "        else:\n",
        "            currAxes = axes[i, j]\n",
        "        if i == 0:\n",
        "            currAxes.set_title(f\"Image {j}\")\n",
        "        if j == 0:\n",
        "            currAxes.text(-0.1, 0.5, folder, rotation=0, va='center', ha='center', transform=currAxes.transAxes)\n",
        "        image_path = os.path.join(image_folder, image)\n",
        "        img = mpimg.imread(image_path)\n",
        "        currAxes.imshow(img, cmap='gray')\n",
        "        currAxes.axis('off')\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.savefig('grid.png', dpi=72)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNG4fd_dTbF"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K6xoHWSsbcS3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#@markdown Make sure you have run the Training cell above before running this cell.\n",
        "import os\n",
        "import random \n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, EulerAncestralDiscreteScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "MODEL_STEPS = 2000 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "if \"PREV_MODEL_STEPS\" not in globals():\n",
        "    raise ValueError(\"Please run the training cell above.\")\n",
        "\n",
        "if not os.path.exists(f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'):\n",
        "    raise ValueError(f\"Model with {MODEL_STEPS} steps does not exist. Please make sure you have run the Training cell above.\")\n",
        "\n",
        "if MODEL_STEPS != PREV_MODEL_STEPS or g_cuda is None:\n",
        "  PREV_MODEL_STEPS = MODEL_STEPS\n",
        "  model_path = f'/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}'             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "  model_path = model_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "  scheduler = EulerAncestralDiscreteScheduler(num_train_timesteps=1000, beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\")\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "  pipe.enable_xformers_memory_efficient_attention()\n",
        "  g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(model_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "SEED = -1  #@param {type:\"number\"}\n",
        "if (SEED < 0):\n",
        "  SEED = random.randint(0, 2**32 - 1) \n",
        "g_cuda.manual_seed(SEED)\n",
        "\n",
        "#@markdown Enter a prompt to generate images from. `{TOKEN_CLASS}` will be replaced with the token and class name.\n",
        "PROMPT = \"photo of {TOKEN_CLASS}\" #@param {type:\"string\"}\n",
        "PROMPT = PROMPT.format(TOKEN_CLASS=f\"{SDD_TOKEN} {SDD_CLASS}\")\n",
        "NEGATIVE_PROMPT = \"\" #@param {type:\"string\"}\n",
        "NUM_SAMPLES = 2 #@param {type:\"number\"}\n",
        "CFG = 8 #@param {type:\"number\"}\n",
        "STEPS = 80 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt=PROMPT,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_images_per_prompt=NUM_SAMPLES,\n",
        "        num_inference_steps=STEPS,\n",
        "        guidance_scale=CFG,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EydphztWBiI"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHvppaFtcFA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if \"SDD_TOKEN\" not in globals():\n",
        "    raise ValueError(\"Please run the Settings cell above.\")\n",
        "\n",
        "#@markdown This will save chosen checkpoint on Google Drive. You can then download it from there.\n",
        "MODEL_STEPS = 2800 #@param {type:\"number\"}\n",
        "mdl_path = f\"/content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}\"\n",
        "mdl_path = mdl_path.replace(\"{TOKEN}\", SDD_TOKEN)\n",
        "ckpt_path =  mdl_path + \"/model.ckpt\"\n",
        "\n",
        "# Make sure model_path exists\n",
        "if not os.path.exists(mdl_path):\n",
        "  raise ValueError(f\"Model with `{MODEL_STEPS}` steps does not exist. Please make sure you have run the training cell above and this model step exist.\")\n",
        "\n",
        "\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $mdl_path  --checkpoint_path $ckpt_path --half\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")\n",
        "\n",
        "# Check if Google Drive is already mounted\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "NAME = \"aivan\" #@param {type:\"string\"}\n",
        "#@markdown Enter the path to save the model in Google Drive. If left empty, the model will be saved in the root of Google Drive.\n",
        "GDRIVE_PATH = \"Files\" #@param {type:\"string\"}\n",
        "\n",
        "# remove / from start and end of GDRIVE_PATH if they exist\n",
        "GDRIVE_PATH = GDRIVE_PATH.strip('/')\n",
        "MODEL_NAME = f\"{SDD_CLASS}-{MODEL_STEPS}-{SDD_TOKEN}-{NAME}\"\n",
        "if GDRIVE_PATH:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{GDRIVE_PATH}/{MODEL_NAME}.ckpt\"\n",
        "else:\n",
        "    cmd = f\"cp /content/stable_diffusion_models/{SDD_TOKEN}/{MODEL_STEPS}/model.ckpt /content/drive/MyDrive/{MODEL_NAME}.ckpt\"\n",
        "\n",
        "# Execute the command\n",
        "!{cmd}\n",
        "print(f\"Model saved at /{GDRIVE_PATH}/{MODEL_NAME}. Wait for 5 minutes before closing\")\n",
        "print(f\"To use your model on other applications make sure to mention \\\"{SDD_TOKEN} {SDD_CLASS}\\\" in the prompt.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXgi8HM4c-DA"
      },
      "outputs": [],
      "source": [
        "#@title Free runtime memory\n",
        "exit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "607db476e417971f05b607c2dd14e77ee8262c2c4c20dea422522c60605a222a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
